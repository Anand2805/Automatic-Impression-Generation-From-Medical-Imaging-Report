{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aLXLnGdAE28G"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ejTpxrG7E28N"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "COChMi1oHHhd",
    "outputId": "456b68f4-76fe-4d8b-9b78-38d761595cf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "csQOWLxWE28T",
    "outputId": "5bec8903-366a-49c1-bfe0-c671cde33c7c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_caption</th>\n",
       "      <th>comparison</th>\n",
       "      <th>indication</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "      <th>findings_count</th>\n",
       "      <th>impression_count</th>\n",
       "      <th>image_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR1_1_IM-0001-3001.png,CXR1_1_IM-0001-4001.png</td>\n",
       "      <td>xray chest pa and lateral</td>\n",
       "      <td>none</td>\n",
       "      <td>positive tb test</td>\n",
       "      <td>the cardiac silhouette and mediastinum size ar...</td>\n",
       "      <td>normal chest x</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR10_IM-0002-1001.png,CXR10_IM-0002-2001.png</td>\n",
       "      <td>pa and lateral chest x</td>\n",
       "      <td>chest radiographs</td>\n",
       "      <td>male chest pain</td>\n",
       "      <td>the cardiomediastinal silhouette is within nor...</td>\n",
       "      <td>no acute cardiopulmonary process</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR100_IM-0002-1001.png,CXR100_IM-0002-2001.png</td>\n",
       "      <td>chest v frontallateral pm</td>\n",
       "      <td>none</td>\n",
       "      <td>no indication</td>\n",
       "      <td>both lungs are clear and expanded heart and me...</td>\n",
       "      <td>no active disease</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR1000_IM-0003-2001.png,CXR1000_IM-0003-1001....</td>\n",
       "      <td>pa and lateral chest x</td>\n",
       "      <td>pa and lateral chest radiographs</td>\n",
       "      <td>male</td>\n",
       "      <td>there is increased opacity within the right up...</td>\n",
       "      <td>increased opacity in the right upper lobe with...</td>\n",
       "      <td>52</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR1001_IM-0004-1002.png,CXR1001_IM-0004-1001.png</td>\n",
       "      <td>chest v frontallateral pm</td>\n",
       "      <td>none</td>\n",
       "      <td>dyspnea subjective fevers arthritis immigrant ...</td>\n",
       "      <td>interstitial markings are diffusely prominent ...</td>\n",
       "      <td>diffuse fibrosis no visible focal acute disease</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_name  \\\n",
       "0    CXR1_1_IM-0001-3001.png,CXR1_1_IM-0001-4001.png   \n",
       "1      CXR10_IM-0002-1001.png,CXR10_IM-0002-2001.png   \n",
       "2    CXR100_IM-0002-1001.png,CXR100_IM-0002-2001.png   \n",
       "3  CXR1000_IM-0003-2001.png,CXR1000_IM-0003-1001....   \n",
       "4  CXR1001_IM-0004-1002.png,CXR1001_IM-0004-1001.png   \n",
       "\n",
       "               image_caption                        comparison  \\\n",
       "0  xray chest pa and lateral                              none   \n",
       "1     pa and lateral chest x                 chest radiographs   \n",
       "2  chest v frontallateral pm                              none   \n",
       "3     pa and lateral chest x  pa and lateral chest radiographs   \n",
       "4  chest v frontallateral pm                              none   \n",
       "\n",
       "                                          indication  \\\n",
       "0                                   positive tb test   \n",
       "1                                    male chest pain   \n",
       "2                                      no indication   \n",
       "3                                               male   \n",
       "4  dyspnea subjective fevers arthritis immigrant ...   \n",
       "\n",
       "                                            findings  \\\n",
       "0  the cardiac silhouette and mediastinum size ar...   \n",
       "1  the cardiomediastinal silhouette is within nor...   \n",
       "2  both lungs are clear and expanded heart and me...   \n",
       "3  there is increased opacity within the right up...   \n",
       "4  interstitial markings are diffusely prominent ...   \n",
       "\n",
       "                                          impression  findings_count  \\\n",
       "0                                     normal chest x              33   \n",
       "1                   no acute cardiopulmonary process              38   \n",
       "2                                  no active disease              10   \n",
       "3  increased opacity in the right upper lobe with...              52   \n",
       "4    diffuse fibrosis no visible focal acute disease              14   \n",
       "\n",
       "   impression_count  image_count  \n",
       "0                 3            2  \n",
       "1                 4            2  \n",
       "2                 3            2  \n",
       "3                36            3  \n",
       "4                 7            2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/indiana-university-chest-xray-png/data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Jd-TaPVSE28Z",
    "outputId": "6bc7f6b6-b78d-47a1-977e-2bddf2898002"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>filename</th>\n",
       "      <th>projection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-4001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_IM-0001-3001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2_IM-0652-2001.dcm.png</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3_IM-1384-1001.dcm.png</td>\n",
       "      <td>Frontal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                filename projection\n",
       "0    1  1_IM-0001-4001.dcm.png    Frontal\n",
       "1    1  1_IM-0001-3001.dcm.png    Lateral\n",
       "2    2  2_IM-0652-1001.dcm.png    Frontal\n",
       "3    2  2_IM-0652-2001.dcm.png    Lateral\n",
       "4    3  3_IM-1384-1001.dcm.png    Frontal"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_projecttions = pd.read_csv(\"/kaggle/input/image-pro/data_projections.csv\")\n",
    "data_projecttions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lqraMhTfVs_F"
   },
   "outputs": [],
   "source": [
    "image_path = \"/kaggle/input/indiana-university-chest-xray-png/NLMCXR_png/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6xx2w2BE28f"
   },
   "source": [
    "# Constructing data point\n",
    "\n",
    "__limiting the data point to 2 images per data point, if we have 5 images, its 4+1 (all image + last image) so make it as 4 data points as below__\n",
    "\n",
    "if i have 5 images then  \n",
    "1 image + 5th image  \n",
    "2nd image + 5th image  \n",
    "3rd image + 5th image  \n",
    "4th image + 5th image   \n",
    "4 data point\n",
    "\n",
    "like wise for other data point,  \n",
    "\n",
    "if i have 3 images then  \n",
    "1st + 3rd  \n",
    "2nd + 3rd  \n",
    "2 data point  \n",
    "\n",
    "if i have 4 images then  \n",
    "1st + 4th  \n",
    "2nd  + 4th  \n",
    "3rd + 4th  \n",
    "3 data point  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZNSO9M6iE28g",
    "outputId": "858343ac-e5a7-4458-ccd6-56b2ee0b39c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3851, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TIBcnIjPE28k",
    "outputId": "faa94524-c7ce-4075-9468-d9a99c04e633"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3208\n",
       "1     446\n",
       "3     181\n",
       "4      15\n",
       "5       1\n",
       "Name: image_count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['image_count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFC-mA3qE28o"
   },
   "source": [
    "__Validate output:__  \n",
    "2 images = 3208  \n",
    "3 images = 181*2   \n",
    "4 images = 15*3  \n",
    "5 images = 1*4  \n",
    "Total    = 3619\n",
    "\n",
    "__Total data point___  \n",
    "\n",
    "we should create duplicate dataframe separately to keep it in all dataset train test validate sets  \n",
    "1 images = 446  \n",
    "3619+446 = 4065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DpMFjyetE28p"
   },
   "outputs": [],
   "source": [
    "def find_Fr_la(li):\n",
    "    \"\"\"Function to find the lateral anf frontal images\n",
    "    Returns All frontal as list and Lateral as last image\"\"\"\n",
    "    img_list = []\n",
    "    last_img = \"\"\n",
    "    for i in li:\n",
    "        projection = data_projecttions[data_projecttions['filename'].str.contains(re.search(r\"\\d.*\\_IM-\\d.*\\.\", i).group())]['projection'].values\n",
    "        if \"Lateral\" == projection:\n",
    "            last_img = i\n",
    "        else:\n",
    "            img_list.append(i)\n",
    "    return img_list, last_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X1TwN7N_E28w",
    "outputId": "93233318-03ec-4ffe-caeb-2e266fea0379"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3851it [00:17, 214.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Report without Lateral images 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating structured data from raw xml files\n",
    "columns = [\"image_1\", \"image_2\", \"impression\"]\n",
    "df = pd.DataFrame(columns = columns)\n",
    "columns = [\"image_1\", \"image_2\", \"impression\"]\n",
    "df_dup = pd.DataFrame(columns = columns)\n",
    "no_lateral = 0\n",
    "for item in tqdm(data.iterrows()):\n",
    "    l = item[1]['image_name'].split(',')\n",
    "    if len(l) > 2:\n",
    "        li, last_img = find_Fr_la(l)\n",
    "        if last_img == \"\":\n",
    "            no_lateral +=1\n",
    "            li, last_img = li[:-1], li[-1]\n",
    "        for i in li:\n",
    "            image_1 = i\n",
    "            image_2 = last_img\n",
    "            df = df.append(pd.Series([image_1, image_2, item[1]['impression']], index = columns), ignore_index = True)\n",
    "    elif len(l) == 2:\n",
    "        image_1 = l[0] \n",
    "        image_2 = l[1]\n",
    "        df = df.append(pd.Series([image_1, image_2, item[1]['impression']], index = columns), ignore_index = True)\n",
    "    elif len(l) == 1:\n",
    "        #creating duplicate dataframe separately to keep it in all dataset train test validate\n",
    "        df_dup = df_dup.append(pd.Series([l[0], l[0], item[1]['impression']], index = columns), ignore_index = True)\n",
    "print(\"Total Report without Lateral images {}\".format(no_lateral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_5t-eSk4E282",
    "outputId": "4d5714a9-b332-4176-849f-09aefcefed8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3532, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hJ1tDI1nE289",
    "outputId": "ec39ec9d-dcaa-4e06-a5d7-04f95b8a7083"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(446, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bPvT88FrE29D"
   },
   "outputs": [],
   "source": [
    "def add_start_end_token(data):\n",
    "    # Combining all the above stundents \n",
    "    preprocessed_reviews_eng = []\n",
    "\n",
    "    # tqdm is for printing the status bar\n",
    "    for sentance in tqdm(data.values):\n",
    "        sentance = '<start> ' + sentance + ' <end>'\n",
    "        preprocessed_reviews_eng.append(sentance.strip())\n",
    "    return preprocessed_reviews_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "j13d3wueE29K",
    "outputId": "7111816e-0fec-4d58-88ce-4a21422c72a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3532/3532 [00:00<00:00, 430322.48it/s]\n",
      "100%|██████████| 446/446 [00:00<00:00, 348548.46it/s]\n"
     ]
    }
   ],
   "source": [
    "df['impression'] = add_start_end_token(df['impression'])\n",
    "df_dup['impression'] = add_start_end_token(df_dup['impression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "umkhT9ATE29V",
    "outputId": "d09fa634-82e2-4daf-b6c7-fad1e51747f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_1</th>\n",
       "      <th>image_2</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR1_1_IM-0001-3001.png</td>\n",
       "      <td>CXR1_1_IM-0001-4001.png</td>\n",
       "      <td>&lt;start&gt; normal chest x &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR10_IM-0002-1001.png</td>\n",
       "      <td>CXR10_IM-0002-2001.png</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary process &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR100_IM-0002-1001.png</td>\n",
       "      <td>CXR100_IM-0002-2001.png</td>\n",
       "      <td>&lt;start&gt; no active disease &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR1000_IM-0003-1001.png</td>\n",
       "      <td>CXR1000_IM-0003-2001.png</td>\n",
       "      <td>&lt;start&gt; increased opacity in the right upper l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR1000_IM-0003-3001.png</td>\n",
       "      <td>CXR1000_IM-0003-2001.png</td>\n",
       "      <td>&lt;start&gt; increased opacity in the right upper l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image_1                   image_2  \\\n",
       "0   CXR1_1_IM-0001-3001.png   CXR1_1_IM-0001-4001.png   \n",
       "1    CXR10_IM-0002-1001.png    CXR10_IM-0002-2001.png   \n",
       "2   CXR100_IM-0002-1001.png   CXR100_IM-0002-2001.png   \n",
       "3  CXR1000_IM-0003-1001.png  CXR1000_IM-0003-2001.png   \n",
       "4  CXR1000_IM-0003-3001.png  CXR1000_IM-0003-2001.png   \n",
       "\n",
       "                                          impression  \n",
       "0                       <start> normal chest x <end>  \n",
       "1     <start> no acute cardiopulmonary process <end>  \n",
       "2                    <start> no active disease <end>  \n",
       "3  <start> increased opacity in the right upper l...  \n",
       "4  <start> increased opacity in the right upper l...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['image_1','image_2', 'impression']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TXz3VUm3E29g",
    "outputId": "370337ae-a14f-4a3e-beeb-3765b23b4ed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3532 entries, 0 to 3531\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image_1     3532 non-null   object\n",
      " 1   image_2     3532 non-null   object\n",
      " 2   impression  3532 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 82.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FMLCdMMoE29y",
    "outputId": "cc76ef86-4cd9-495d-f3a2-44fc43237043"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_1</th>\n",
       "      <th>image_2</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR1003_IM-0005-2002.png</td>\n",
       "      <td>CXR1003_IM-0005-2002.png</td>\n",
       "      <td>&lt;start&gt; retrocardiac soft tissue density the a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR1012_IM-0013-1001.png</td>\n",
       "      <td>CXR1012_IM-0013-1001.png</td>\n",
       "      <td>&lt;start&gt; bibasilar airspace disease and bilater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR1024_IM-0019-1001.png</td>\n",
       "      <td>CXR1024_IM-0019-1001.png</td>\n",
       "      <td>&lt;start&gt; no acute abnormality &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR1026_IM-0021-2002.png</td>\n",
       "      <td>CXR1026_IM-0021-2002.png</td>\n",
       "      <td>&lt;start&gt; no acute cardiopulmonary disease &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR1029_IM-0022-1001.png</td>\n",
       "      <td>CXR1029_IM-0022-1001.png</td>\n",
       "      <td>&lt;start&gt; no pneumonia heart size normal scolios...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    image_1                   image_2  \\\n",
       "0  CXR1003_IM-0005-2002.png  CXR1003_IM-0005-2002.png   \n",
       "1  CXR1012_IM-0013-1001.png  CXR1012_IM-0013-1001.png   \n",
       "2  CXR1024_IM-0019-1001.png  CXR1024_IM-0019-1001.png   \n",
       "3  CXR1026_IM-0021-2002.png  CXR1026_IM-0021-2002.png   \n",
       "4  CXR1029_IM-0022-1001.png  CXR1029_IM-0022-1001.png   \n",
       "\n",
       "                                          impression  \n",
       "0  <start> retrocardiac soft tissue density the a...  \n",
       "1  <start> bibasilar airspace disease and bilater...  \n",
       "2                 <start> no acute abnormality <end>  \n",
       "3     <start> no acute cardiopulmonary disease <end>  \n",
       "4  <start> no pneumonia heart size normal scolios...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup[['image_1','image_2', 'impression']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5WxvLnbJE2-B",
    "outputId": "1f30c98e-9e7f-4906-e912-f375abd87ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 446 entries, 0 to 445\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image_1     446 non-null    object\n",
      " 1   image_2     446 non-null    object\n",
      " 2   impression  446 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 10.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2G681txjE2-J",
    "outputId": "6e18d75b-f44c-4315-be31-68d9e7931d8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3851/3851 [00:00<00:00, 321783.90it/s]\n"
     ]
    }
   ],
   "source": [
    "image_name = []\n",
    "for img in tqdm(data['image_name'].str.split(',')):\n",
    "    for i in range(len(img)):\n",
    "        image_name.append(img[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WAkfuGYrVIWg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "image_features_model = InceptionV3(include_top=False, weights='imagenet', pooling='avg', input_shape=(299,299,3))\n",
    "image_features_model.load_weights(\"../input/trained/trained_weights-07-0.9102.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "J8qvs0zTE2-S",
    "outputId": "1519af62-e85a-4a3c-80cd-5bff416cdcec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7470/7470 [15:52<00:00,  7.85it/s]\n"
     ]
    }
   ],
   "source": [
    "img_tensor = []\n",
    "for img in tqdm(image_name):\n",
    "    img = tf.io.read_file(image_path + str(img))\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    img = preprocess_input(img)\n",
    "    img_features = image_features_model(tf.constant(img)[None, :])\n",
    "    img_tensor.append(img_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bvmwff_nE2-c"
   },
   "source": [
    "# Train Test and Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aVvJaNIlHHi9"
   },
   "outputs": [],
   "source": [
    "##fixing numpy RS\n",
    "np.random.seed(42)\n",
    "##fixing tensorflow RS\n",
    "tf.random.set_seed(32)\n",
    "##python RS\n",
    "rn.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "eLQWhLxeE2-k",
    "outputId": "c791c119-5ba9-4ed9-bf2a-55a4b5e32cf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2542, 2), (2542,), (636, 2), (636,), (354, 2), (354,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_train, input_test, o_train, output_test = train_test_split(df[['image_1','image_2']].values, df['impression'].values, test_size=0.1, random_state=15)\n",
    "input_train, input_val, output_train, output_val = train_test_split(i_train, o_train, test_size=0.2, random_state=15)\n",
    "input_train.shape, output_train.shape, input_val.shape, output_val.shape, input_test.shape, output_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AdC9nHGE2-x"
   },
   "source": [
    "- Train test and validation split for duplicate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oLrQ8_F5E2-y",
    "outputId": "b81087e6-101f-43d5-8bb1-df9720365ebd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 2), (320,), (81, 2), (81,), (45, 2), (45,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_train_dup, input_test_dup, o_train_dup, output_test_dup = train_test_split(df_dup[['image_1','image_2']].values, df_dup['impression'].values, test_size=0.1, random_state=15)\n",
    "input_train_dup, input_val_dup, output_train_dup, output_val_dup = train_test_split(i_train_dup, o_train_dup, test_size=0.2, random_state=15)\n",
    "input_train_dup.shape, output_train_dup.shape, input_val_dup.shape, output_val_dup.shape, input_test_dup.shape, output_test_dup.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqLSJEdwE2-6"
   },
   "source": [
    "- Append duplicate data equally with train, test, and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uvoPStRzE2-7",
    "outputId": "f7c430fc-640b-4c25-f7df-c829365f48d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Final data point shape =====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2862, 2), (2862,), (717, 2), (717,), (399, 2), (399,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_train = np.append(input_train, input_train_dup, axis=0)\n",
    "out_train = np.append(output_train, output_train_dup, axis=0)\n",
    "in_val = np.append(input_val, input_val_dup, axis=0)\n",
    "out_val = np.append(output_val, output_val_dup, axis=0)\n",
    "in_test = np.append(input_test, input_test_dup, axis=0)\n",
    "out_test = np.append(output_test, output_test_dup, axis=0)\n",
    "print(\"===== Final data point shape =====\")\n",
    "in_train.shape, out_train.shape, in_val.shape, out_val.shape, in_test.shape, out_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rturBoigE2_D"
   },
   "source": [
    "#### Shuffle the data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Y8vXL9qSE2_D"
   },
   "outputs": [],
   "source": [
    "# Shuffle captions and image_names together\n",
    "# Set a random state\n",
    "for i in range(3):\n",
    "    in_train, out_train = shuffle(in_train, out_train, random_state=15)\n",
    "    in_val, out_val = shuffle(in_val, out_val, random_state=15)\n",
    "    in_test, out_test = shuffle(in_test, out_test, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0EJ28lNhE2_R"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len_output = 80\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(oov_token=\"<unk>\", filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(out_train)\n",
    "text_train = tokenizer.texts_to_sequences(out_train)\n",
    "text_test = tokenizer.texts_to_sequences(out_test)\n",
    "text_val = tokenizer.texts_to_sequences(out_val)\n",
    "dictionary = tokenizer.word_index\n",
    "\n",
    "word2idx = {}\n",
    "idx2word = {}\n",
    "for k, v in dictionary.items(): \n",
    "    word2idx[k] = v\n",
    "    idx2word[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ZknUTQfGE2_e",
    "outputId": "496b91b1-e6c7-44a6-f3e4-e581d0aef0bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1339"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word2idx)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "8fuak5kTE2_k",
    "outputId": "255d67df-4d2e-4f26-ee9e-e104e30449a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Top 6 Word and its Index =====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('<unk>', 1),\n",
       " ('<start>', 2),\n",
       " ('<end>', 3),\n",
       " ('no', 4),\n",
       " ('acute', 5),\n",
       " ('cardiopulmonary', 6)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"===== Top 6 Word and its Index =====\")\n",
    "list(dictionary.items())[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "gLOrsXIhE2_s"
   },
   "outputs": [],
   "source": [
    "text_output_train = pad_sequences(text_train, maxlen=max_len_output, dtype='int32', padding='post', truncating='post')\n",
    "text_output_val = pad_sequences(text_val, maxlen=max_len_output, dtype='int32', padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "EQlf4fc3E2_1",
    "outputId": "60697195-ba56-42d4-b0ff-b8715fe950d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2862, 80)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_output_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "gmq0uz14E2_-"
   },
   "outputs": [],
   "source": [
    "def multi_image(img, imp):\n",
    "    return tf.convert_to_tensor([img_tensor[image_name.index(img[0].decode('utf-8'))], img_tensor[image_name.index(img[1].decode('utf-8'))]]), imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "L95wUXh-E3AH",
    "outputId": "b8462cfb-3f62-446a-b797-8fab508820fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CXR1391_IM-0250-1001.png', 'CXR1391_IM-0250-5001.png'],\n",
       "       dtype=object),\n",
       " array([ 2, 67, 28, 74, 88, 22,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_train[0], text_output_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "NUm9wrSAcPrD"
   },
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((in_train, text_output_train))\n",
    "\n",
    "# Use map to load the numpy files in parallel\n",
    "dataset_train = dataset_train.map(lambda item1, item2: tf.numpy_function(\n",
    "          multi_image, [item1, item2], [tf.float32, tf.int32]),\n",
    "          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((in_val, text_output_val))\n",
    "\n",
    "# Use map to load the numpy files in parallel\n",
    "dataset_val = dataset_val.map(lambda item1, item2: tf.numpy_function(\n",
    "          multi_image, [item1, item2], [tf.float32, tf.int32]),\n",
    "          num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "2bWNf3_pdbPb"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "embedding_dim = 256\n",
    "units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "TVD43-gPcdzr"
   },
   "outputs": [],
   "source": [
    "# Shuffle and batch Train\n",
    "dataset_train = dataset_train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "dataset_train = dataset_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "# Shuffle and batch Validation\n",
    "dataset_val = dataset_val.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "dataset_val = dataset_val.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "x5uEOI9IeOlD"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dense = tf.keras.layers.Dense(embedding_dim, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45))\n",
    "\n",
    "    def call(self, x):\n",
    "        # CNN two input Images concatenate to get single vector\n",
    "        # Concatenating 2 images\n",
    "        # Input x shape (batch_size, 2,None,2048)\n",
    "        # x1 shape (batch_size, None, 2048)\n",
    "        # x2 shape (batch_size, None, 2048)\n",
    "        encoder_concat = tf.keras.layers.concatenate([x[:,0], x[:,1]])\n",
    "        x = self.dense(encoder_concat)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "ruzWbIhbfqlG"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.w_1 = tf.keras.layers.Dense(units)\n",
    "        self.w_2 = tf.keras.layers.Dense(units)\n",
    "        # Bidirectional LSTM\n",
    "        self.bilstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM \\\n",
    "                                      (self.units, dropout=0.3, return_sequences=True, return_state=True, \\\n",
    "                                       #kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.001), \\\n",
    "                                       recurrent_activation='relu', recurrent_initializer= \\\n",
    "                                       tf.keras.initializers.glorot_uniform(seed=26)))\n",
    "        self.bilstm_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM\\\n",
    "                                      (self.units, dropout=0.2, return_sequences=True, return_state=True, \\\n",
    "                                       #kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.001), \\\n",
    "                                       recurrent_activation='relu', recurrent_initializer= \\\n",
    "                                       tf.keras.initializers.glorot_uniform(seed=26)))\n",
    "        self.dense_1 = tf.keras.layers.Dense(self.units, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45))\n",
    "        self.dense_2 = tf.keras.layers.Dense(vocab_size, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45))\n",
    "        #Additive Attention\n",
    "        self.attention = tf.keras.layers.AdditiveAttention(self.units)\n",
    "    def call(self, x):\n",
    "        # x = [dec_input, features, hidden] [decoder_input_word_tensor, encoder_output, hidden_state_previous]\n",
    "        embedded_layer = self.embedding(x[0])\n",
    "        x_con = tf.concat([embedded_layer, x[1]], axis=-1)\n",
    "        bi_lstm = self.bilstm_1(x_con)\n",
    "        lstm, forward_h, forward_c, backward_h, backward_c = self.bilstm_2(bi_lstm)\n",
    "        state = tf.keras.layers.Concatenate()([forward_h, backward_h])\n",
    "        state = tf.keras.layers.Concatenate()([state,x[2]])\n",
    "        state = self.w_1(state)\n",
    "        lstm = self.w_2(lstm)\n",
    "        additive = self.attention([lstm,state])\n",
    "        #decoder_1_1/additive_attention_1/Identity_1:0, shape=(None, 1, 128)\n",
    "        #Reshaping to (None, 128)\n",
    "        output = tf.reshape(additive, (-1, additive.shape[2]))\n",
    "        output = self.dense_1(output)\n",
    "        output = self.dense_2(output)\n",
    "        # output will be (None, 1339)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "hhlAbu29fqlJ"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "gmomeMJpfqlM",
    "outputId": "8f8451ed-5c47-4e28-a0a6-2197cb6eae6d"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(embedding_dim, units, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "D6mTk-WueUOG"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "acc_obj = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "def loss_func(real, pred):\n",
    "    loss_f = loss_obj(real, pred)\n",
    "    return tf.reduce_mean(loss_f)\n",
    "\n",
    "\n",
    "def acc_func(real, pred):\n",
    "    acc_f = acc_obj(real, pred)\n",
    "    return tf.reduce_mean(acc_f)\n",
    "\n",
    "@tf.function\n",
    "def bleu_func(real, pred):\n",
    "    return sentence_bleu([real], pred, weights=(1.0, 0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../working': Device or resource busy\n"
     ]
    }
   ],
   "source": [
    "!rm -r ../working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "y-tP50NsHHkQ"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = '../working/logs/' + current_time + '/train'\n",
    "val_log_dir = '../working/logs/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "val_summary_writer = tf.summary.create_file_writer(val_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "-LGzCaBYgLdA"
   },
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "@tf.function\n",
    "def train_step(tensor, target):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    # initializing the hidden state for each batch\n",
    "    hidden =  tf.zeros((target.shape[0], units))\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
    "    actual, predicted = list(), list()\n",
    "    with tf.GradientTape() as tape:\n",
    "        features = encoder(tensor)\n",
    "        for i in range(1, target.shape[1]):\n",
    "            # passing the features through the decoder\n",
    "            predictions, hidden = decoder([dec_input, features, hidden])\n",
    "            loss += loss_func(target[:, i], predictions)\n",
    "            accuracy += acc_func(target[:, i], predictions)\n",
    "            pred = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
    "            act = target[:, i][0].numpy()\n",
    "\n",
    "            if act !=0:\n",
    "                actual.append(tokenizer.index_word[act])\n",
    "            if pred !=0:\n",
    "                predicted.append(tokenizer.index_word[pred])\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "    \n",
    "    total_loss = (loss / int(target.shape[1]))\n",
    "    total_acc = (accuracy / int(target.shape[1]))\n",
    "    total_bleu = bleu_func(actual,predicted)\n",
    "    \n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss, total_loss, total_acc, total_bleu\n",
    "\n",
    "#validation function\n",
    "@tf.function\n",
    "def val_step(tensor, target):\n",
    "    loss_val = 0\n",
    "    accuracy_val = 0\n",
    "    # initializing the hidden state for each batch\n",
    "    hidden =  tf.zeros((target.shape[0], units))\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * target.shape[0], 1)\n",
    "    actual, predicted = list(), list()\n",
    "    with tf.GradientTape() as tape:\n",
    "        features = encoder(tensor)\n",
    "        for i in range(1, target.shape[1]):\n",
    "            # passing the features through the decoder\n",
    "            predictions_val, hidden = decoder([dec_input, features, hidden])\n",
    "            loss_val += loss_func(target[:, i], predictions_val)\n",
    "            accuracy_val += acc_func(target[:, i], predictions_val)\n",
    "            \n",
    "            pred = tf.random.categorical(predictions_val, 1)[0][0].numpy()\n",
    "            act = target[:, i][0].numpy()\n",
    "            if act !=0:\n",
    "                actual.append(tokenizer.index_word[act])\n",
    "            if pred !=0:\n",
    "                predicted.append(tokenizer.index_word[pred])\n",
    "                \n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "    total_loss_val = (loss_val / int(target.shape[1]))\n",
    "    total_acc_val = (accuracy_val / int(target.shape[1]))\n",
    "    total_bleu_val = bleu_func(actual,predicted)\n",
    "    return loss_val, total_loss_val, total_acc_val, total_bleu_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "2dxRHe8tgb6b",
    "outputId": "b8dbb62e-e016-4d27-acfb-0c1912cb7207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Start Epoch 1 ========\n",
      "Train loss\n",
      "Epoch 1 Batch 0 Loss 7.1097 acc 0.0000 bleu 0.000000\n",
      "Epoch 1 Batch 40 Loss 0.6830 acc 0.8304 bleu 0.400000\n",
      "Epoch 1 Batch 80 Loss 0.7917 acc 0.8498 bleu 0.222222\n",
      "Validation loss\n",
      "Epoch 1 Batch 0 Loss 0.6734 acc 0.8522 bleu 0.100000\n",
      "Epoch 1, Loss: 1.2359944581985474, Accuracy: 80.92428588867188, Bleu: 0.12869112913276862, Test Loss: 0.9599607586860657, Test Accuracy: 89.18602752685547, Test Bleu: 0.14990489836990525\n",
      "====== Start Epoch 2 ========\n",
      "Train loss\n",
      "Epoch 2 Batch 0 Loss 0.7833 acc 0.8546 bleu 0.040337\n",
      "Epoch 2 Batch 40 Loss 0.6242 acc 0.8582 bleu 0.222222\n",
      "Epoch 2 Batch 80 Loss 0.9100 acc 0.8618 bleu 0.121138\n",
      "Validation loss\n",
      "Epoch 2 Batch 0 Loss 1.0406 acc 0.8619 bleu 0.142857\n",
      "Epoch 2, Loss: 0.8615699410438538, Accuracy: 86.8127670288086, Bleu: 0.18031143164697244, Test Loss: 0.9142494201660156, Test Accuracy: 90.11295318603516, Test Bleu: 0.1475350355721103\n",
      "====== Start Epoch 3 ========\n",
      "Train loss\n",
      "Epoch 3 Batch 0 Loss 0.8194 acc 0.8623 bleu 0.000000\n",
      "Epoch 3 Batch 40 Loss 0.6259 acc 0.8637 bleu 0.333333\n",
      "Epoch 3 Batch 80 Loss 0.8384 acc 0.8654 bleu 0.200000\n",
      "Validation loss\n",
      "Epoch 3 Batch 0 Loss 0.8435 acc 0.8661 bleu 0.181818\n",
      "Epoch 3, Loss: 0.7406553030014038, Accuracy: 87.35159301757812, Bleu: 0.20851755233738337, Test Loss: 0.6936392188072205, Test Accuracy: 90.5828628540039, Test Bleu: 0.23524048462747443\n",
      "====== Start Epoch 4 ========\n",
      "Train loss\n",
      "Epoch 4 Batch 0 Loss 0.8288 acc 0.8668 bleu 0.142857\n",
      "Epoch 4 Batch 40 Loss 0.4540 acc 0.8681 bleu 0.250000\n",
      "Epoch 4 Batch 80 Loss 0.4346 acc 0.8696 bleu 0.375000\n",
      "Validation loss\n",
      "Epoch 4 Batch 0 Loss 0.6268 acc 0.8701 bleu 0.300000\n",
      "Epoch 4, Loss: 0.6141421794891357, Accuracy: 87.81070709228516, Bleu: 0.25637992213098604, Test Loss: 0.6718891263008118, Test Accuracy: 90.99249267578125, Test Bleu: 0.27299177546213116\n",
      "====== Start Epoch 5 ========\n",
      "Train loss\n",
      "Epoch 5 Batch 0 Loss 0.5270 acc 0.8704 bleu 0.600000\n",
      "Epoch 5 Batch 40 Loss 0.6702 acc 0.8713 bleu 0.500000\n",
      "Epoch 5 Batch 80 Loss 0.5889 acc 0.8725 bleu 0.142857\n",
      "Validation loss\n",
      "Epoch 5 Batch 0 Loss 0.6819 acc 0.8728 bleu 0.500000\n",
      "Epoch 5, Loss: 0.5819327235221863, Accuracy: 88.13544464111328, Bleu: 0.2978844026518143, Test Loss: 0.6537286639213562, Test Accuracy: 91.2597885131836, Test Bleu: 0.37893128926878766\n",
      "====== Start Epoch 6 ========\n",
      "Train loss\n",
      "Epoch 6 Batch 0 Loss 0.8618 acc 0.8730 bleu 0.000000\n",
      "Epoch 6 Batch 40 Loss 0.7342 acc 0.8736 bleu 0.315789\n",
      "Epoch 6 Batch 80 Loss 0.6030 acc 0.8746 bleu 0.400000\n",
      "Validation loss\n",
      "Epoch 6 Batch 0 Loss 0.4664 acc 0.8749 bleu 0.000000\n",
      "Epoch 6, Loss: 0.5597649812698364, Accuracy: 88.3617935180664, Bleu: 0.3303681533667782, Test Loss: 0.640234649181366, Test Accuracy: 91.48302459716797, Test Bleu: 0.3537844508432744\n",
      "====== Start Epoch 7 ========\n",
      "Train loss\n",
      "Epoch 7 Batch 0 Loss 0.4437 acc 0.8751 bleu 0.100000\n",
      "Epoch 7 Batch 40 Loss 0.4768 acc 0.8756 bleu 0.750000\n",
      "Epoch 7 Batch 80 Loss 0.5263 acc 0.8766 bleu 0.400000\n",
      "Validation loss\n",
      "Epoch 7 Batch 0 Loss 0.4515 acc 0.8767 bleu 0.166667\n",
      "Epoch 7, Loss: 0.5507299304008484, Accuracy: 88.55825805664062, Bleu: 0.32846693280730654, Test Loss: 0.6210996508598328, Test Accuracy: 91.66143798828125, Test Bleu: 0.30815993672759\n",
      "====== Start Epoch 8 ========\n",
      "Train loss\n",
      "Epoch 8 Batch 0 Loss 0.3235 acc 0.8769 bleu 0.333333\n",
      "Epoch 8 Batch 40 Loss 0.5925 acc 0.8756 bleu 0.600000\n",
      "Epoch 8 Batch 80 Loss 0.5051 acc 0.8763 bleu 0.600000\n",
      "Validation loss\n",
      "Epoch 8 Batch 0 Loss 0.4814 acc 0.8764 bleu 0.000000\n",
      "Epoch 8, Loss: 0.6368206143379211, Accuracy: 88.60269927978516, Bleu: 0.3200495132124192, Test Loss: 0.6358524560928345, Test Accuracy: 91.63407897949219, Test Bleu: 0.3354840783295055\n",
      "\n",
      "******count++ Increased******\n",
      "\n",
      "====== Start Epoch 9 ========\n",
      "Train loss\n",
      "Epoch 9 Batch 0 Loss 0.5910 acc 0.8765 bleu 0.250000\n",
      "Epoch 9 Batch 40 Loss 0.4551 acc 0.8772 bleu 0.666667\n",
      "Epoch 9 Batch 80 Loss 0.3572 acc 0.8778 bleu 0.500000\n",
      "Validation loss\n",
      "Epoch 9 Batch 0 Loss 0.4639 acc 0.8779 bleu 0.096774\n",
      "Epoch 9, Loss: 0.5310754776000977, Accuracy: 88.71011352539062, Bleu: 0.3629458119370923, Test Loss: 0.6256089210510254, Test Accuracy: 91.786865234375, Test Bleu: 0.3621890699371367\n",
      "====== Start Epoch 10 ========\n",
      "Train loss\n",
      "Epoch 10 Batch 0 Loss 0.4101 acc 0.8781 bleu 0.333333\n",
      "Epoch 10 Batch 40 Loss 0.9331 acc 0.8785 bleu 0.222222\n",
      "Epoch 10 Batch 80 Loss 0.4604 acc 0.8791 bleu 0.500000\n",
      "Validation loss\n",
      "Epoch 10 Batch 0 Loss 0.8182 acc 0.8794 bleu 0.666667\n",
      "Epoch 10, Loss: 0.5031968355178833, Accuracy: 88.851806640625, Bleu: 0.38227916575420534, Test Loss: 0.598798394203186, Test Accuracy: 91.94219207763672, Test Bleu: 0.38362243816789277\n",
      "====== Start Epoch 11 ========\n",
      "Train loss\n",
      "Epoch 11 Batch 0 Loss 0.6003 acc 0.8796 bleu 0.133333\n",
      "Epoch 11 Batch 40 Loss 0.3425 acc 0.8801 bleu 0.800000\n",
      "Epoch 11 Batch 80 Loss 0.3806 acc 0.8809 bleu 0.100000\n",
      "Validation loss\n",
      "Epoch 11 Batch 0 Loss 0.5676 acc 0.8809 bleu 0.111111\n",
      "Epoch 11, Loss: 0.48742929100990295, Accuracy: 89.01469421386719, Bleu: 0.3771536767982669, Test Loss: 0.5663123726844788, Test Accuracy: 92.10516357421875, Test Bleu: 0.3494217411622345\n",
      "====== Start Epoch 12 ========\n",
      "Train loss\n",
      "Epoch 12 Batch 0 Loss 0.6639 acc 0.8811 bleu 0.160000\n",
      "Epoch 12 Batch 40 Loss 0.5215 acc 0.8816 bleu 0.000000\n",
      "Epoch 12 Batch 80 Loss 0.5672 acc 0.8823 bleu 0.600000\n",
      "Validation loss\n",
      "Epoch 12 Batch 0 Loss 0.5444 acc 0.8824 bleu 0.400000\n",
      "Epoch 12, Loss: 0.46685323119163513, Accuracy: 89.16455841064453, Bleu: 0.39096066951004366, Test Loss: 0.5628733038902283, Test Accuracy: 92.26698303222656, Test Bleu: 0.4200558213716109\n",
      "====== Start Epoch 13 ========\n",
      "Train loss\n",
      "Epoch 13 Batch 0 Loss 0.6116 acc 0.8826 bleu 0.333333\n",
      "Epoch 13 Batch 40 Loss 0.4340 acc 0.8830 bleu 0.250000\n",
      "Epoch 13 Batch 80 Loss 0.6856 acc 0.8837 bleu 0.200000\n",
      "Validation loss\n",
      "Epoch 13 Batch 0 Loss 0.5528 acc 0.8839 bleu 0.400000\n",
      "Epoch 13, Loss: 0.44690442085266113, Accuracy: 89.30831146240234, Bleu: 0.41892484099262234, Test Loss: 0.5575191974639893, Test Accuracy: 92.4183120727539, Test Bleu: 0.5169545870488221\n",
      "====== Start Epoch 14 ========\n",
      "Train loss\n",
      "Epoch 14 Batch 0 Loss 0.5197 acc 0.8841 bleu 0.400000\n",
      "Epoch 14 Batch 40 Loss 0.4255 acc 0.8845 bleu 0.000000\n",
      "Epoch 14 Batch 80 Loss 0.2721 acc 0.8851 bleu 0.400000\n",
      "Validation loss\n",
      "Epoch 14 Batch 0 Loss 0.5156 acc 0.8853 bleu 0.181818\n",
      "Epoch 14, Loss: 0.4299962818622589, Accuracy: 89.45791625976562, Bleu: 0.40251193355555365, Test Loss: 0.5559608340263367, Test Accuracy: 92.5602035522461, Test Bleu: 0.4424816548338924\n",
      "====== Start Epoch 15 ========\n",
      "Train loss\n",
      "Epoch 15 Batch 0 Loss 0.8251 acc 0.8854 bleu 0.500000\n",
      "Epoch 15 Batch 40 Loss 0.3567 acc 0.8859 bleu 0.800000\n",
      "Epoch 15 Batch 80 Loss 0.3885 acc 0.8865 bleu 0.176471\n",
      "Validation loss\n",
      "Epoch 15 Batch 0 Loss 0.5359 acc 0.8866 bleu 0.800000\n",
      "Epoch 15, Loss: 0.41602590680122375, Accuracy: 89.59064483642578, Bleu: 0.42973844316683907, Test Loss: 0.556716799736023, Test Accuracy: 92.69609069824219, Test Bleu: 0.4137771402322057\n",
      "\n",
      "******count++ Increased******\n",
      "\n",
      "====== Start Epoch 16 ========\n",
      "Train loss\n",
      "Epoch 16 Batch 0 Loss 0.5122 acc 0.8867 bleu 0.279070\n",
      "Epoch 16 Batch 40 Loss 0.3841 acc 0.8872 bleu 0.200000\n",
      "Epoch 16 Batch 80 Loss 0.3705 acc 0.8877 bleu 0.400000\n",
      "Validation loss\n",
      "Epoch 16 Batch 0 Loss 0.6084 acc 0.8878 bleu 0.600000\n",
      "Epoch 16, Loss: 0.4045845568180084, Accuracy: 89.72522735595703, Bleu: 0.43779813662326716, Test Loss: 0.5524859428405762, Test Accuracy: 92.8255844116211, Test Bleu: 0.42678351060704006\n",
      "====== Start Epoch 17 ========\n",
      "Train loss\n",
      "Epoch 17 Batch 0 Loss 0.4840 acc 0.8880 bleu 0.333333\n",
      "Epoch 17 Batch 40 Loss 0.3718 acc 0.8884 bleu 0.600000\n",
      "Epoch 17 Batch 80 Loss 0.2960 acc 0.8889 bleu 0.500000\n",
      "Validation loss\n",
      "Epoch 17 Batch 0 Loss 0.5825 acc 0.8890 bleu 0.400000\n",
      "Epoch 17, Loss: 0.3880102038383484, Accuracy: 89.84420013427734, Bleu: 0.4455547190188083, Test Loss: 0.5304186344146729, Test Accuracy: 92.95114135742188, Test Bleu: 0.4132144925748548\n",
      "====== Start Epoch 18 ========\n",
      "Train loss\n",
      "Epoch 18 Batch 0 Loss 0.5074 acc 0.8891 bleu 0.400000\n",
      "Epoch 18 Batch 40 Loss 0.2732 acc 0.8896 bleu 0.400000\n",
      "Epoch 18 Batch 80 Loss 0.3433 acc 0.8900 bleu 0.500000\n",
      "Validation loss\n",
      "Epoch 18 Batch 0 Loss 0.3530 acc 0.8901 bleu 0.250000\n",
      "Epoch 18, Loss: 0.3783934414386749, Accuracy: 89.95836639404297, Bleu: 0.429573929630094, Test Loss: 0.5293744802474976, Test Accuracy: 93.06478881835938, Test Bleu: 0.44114357864357867\n",
      "====== Start Epoch 19 ========\n",
      "Train loss\n",
      "Epoch 19 Batch 0 Loss 0.5333 acc 0.8902 bleu 0.600000\n",
      "Epoch 19 Batch 40 Loss 0.5161 acc 0.8906 bleu 0.750000\n",
      "Epoch 19 Batch 80 Loss 0.2299 acc 0.8911 bleu 0.600000\n",
      "Validation loss\n",
      "Epoch 19 Batch 0 Loss 0.4500 acc 0.8912 bleu 0.600000\n",
      "Epoch 19, Loss: 0.36667293310165405, Accuracy: 90.06817626953125, Bleu: 0.4592081144168486, Test Loss: 0.5347850918769836, Test Accuracy: 93.17817687988281, Test Bleu: 0.473839883910415\n",
      "\n",
      "******count++ Increased******\n",
      "\n",
      "====== Start Epoch 20 ========\n",
      "Train loss\n",
      "Epoch 20 Batch 0 Loss 0.4736 acc 0.8913 bleu 0.250000\n",
      "Epoch 20 Batch 40 Loss 0.2351 acc 0.8917 bleu 0.262295\n",
      "Epoch 20 Batch 80 Loss 0.4745 acc 0.8921 bleu 0.400000\n",
      "Validation loss\n",
      "Epoch 20 Batch 0 Loss 0.4535 acc 0.8922 bleu 0.266667\n",
      "Epoch 20, Loss: 0.35714417695999146, Accuracy: 90.17404174804688, Bleu: 0.4512459829514771, Test Loss: 0.5289786458015442, Test Accuracy: 93.28365325927734, Test Bleu: 0.4753914845337132\n",
      "====== Start Epoch 21 ========\n",
      "Train loss\n",
      "Epoch 21 Batch 0 Loss 0.2813 acc 0.8923 bleu 0.250000\n",
      "Epoch 21 Batch 40 Loss 0.2436 acc 0.8927 bleu 0.428571\n",
      "Epoch 21 Batch 80 Loss 0.2840 acc 0.8931 bleu 0.250000\n",
      "Validation loss\n",
      "Epoch 21 Batch 0 Loss 0.5622 acc 0.8932 bleu 0.800000\n",
      "Epoch 21, Loss: 0.3468414843082428, Accuracy: 90.2762222290039, Bleu: 0.5133468137683631, Test Loss: 0.5334436893463135, Test Accuracy: 93.38290405273438, Test Bleu: 0.5055155008063328\n",
      "\n",
      "******count++ Increased******\n",
      "\n",
      "====== Start Epoch 22 ========\n",
      "Train loss\n",
      "Epoch 22 Batch 0 Loss 0.4208 acc 0.8933 bleu 0.777778\n",
      "Epoch 22 Batch 40 Loss 0.3682 acc 0.8937 bleu 0.625000\n",
      "Epoch 22 Batch 80 Loss 0.2438 acc 0.8940 bleu 0.375000\n",
      "Validation loss\n",
      "Epoch 22 Batch 0 Loss 0.3928 acc 0.8941 bleu 0.500000\n",
      "Epoch 22, Loss: 0.3373640775680542, Accuracy: 90.37554168701172, Bleu: 0.45593196362949534, Test Loss: 0.5334764719009399, Test Accuracy: 93.48220825195312, Test Bleu: 0.5193265981276948\n",
      "\n",
      "\n",
      "EarlyStopping Invoked!!! Stopping the training\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "val_loss_history = []\n",
    "count = 0\n",
    "for epoch in range(0, EPOCHS):\n",
    "    print(\"====== Start Epoch \" +str(epoch + 1)+ \" ========\")\n",
    "    \n",
    "    total_loss_train = 0\n",
    "    total_acc_train = 0\n",
    "    total_bleu_train = 0\n",
    "    total_loss_val = 0\n",
    "    total_acc_val = 0\n",
    "    total_bleu_val = 0\n",
    "    print('Train loss')\n",
    "    for (batch, (jpg_tensor, target)) in enumerate(dataset_train):\n",
    "        batch_loss, t_loss, t_acc, t_bleu = train_step(jpg_tensor, target)\n",
    "        total_loss_train += t_loss\n",
    "        total_acc_train += t_acc\n",
    "        total_bleu_train += t_bleu\n",
    "        if batch % 40 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} acc {:.4f} bleu {:.6f}'.format(\n",
    "              epoch + 1, batch, batch_loss / int(target.shape[1]), t_acc, t_bleu))\n",
    "    \n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', total_loss_train/ int(len(in_train) // BATCH_SIZE), step=epoch)\n",
    "        tf.summary.scalar('accuracy', total_acc_train/ int(len(in_train) // BATCH_SIZE), step=epoch)\n",
    "        tf.summary.scalar('bleu', total_bleu_train/ int(len(in_train) // BATCH_SIZE), step=epoch)\n",
    "\n",
    "    #validation\n",
    "    print('Validation loss')\n",
    "    for (batch, (jpg_tensor, target)) in enumerate(dataset_val):\n",
    "        batch_loss_val, t_loss_val, t_acc_val, t_bleu_val = val_step(jpg_tensor, target)\n",
    "        total_loss_val += t_loss_val\n",
    "        total_acc_val += t_acc_val\n",
    "        total_bleu_val += t_bleu_val\n",
    "        \n",
    "        if batch % 40 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} acc {:.4f} bleu {:.6f}'.format(\n",
    "              epoch + 1, batch, batch_loss_val / int(target.shape[1]), t_acc_val, t_bleu_val))\n",
    "    \n",
    "    with val_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', total_loss_val/int(len(in_val) // BATCH_SIZE), step=epoch)\n",
    "        tf.summary.scalar('accuracy', total_acc_val/int(len(in_val) // BATCH_SIZE), step=epoch)\n",
    "        tf.summary.scalar('bleu', total_bleu_val/int(len(in_val) // BATCH_SIZE), step=epoch)\n",
    "\n",
    "    print ('Epoch {}, Loss: {}, Accuracy: {}, Bleu: {}, Test Loss: {}, Test Accuracy: {}, Test Bleu: {}'.format(epoch+1, \n",
    "                            total_loss_train/ int(len(in_train) // BATCH_SIZE), \n",
    "                            (total_acc_train/ int(len(in_train) // BATCH_SIZE))*100, total_bleu_train/ int(len(in_train) // BATCH_SIZE),                                                                    \n",
    "                            total_loss_val/int(len(in_val) // BATCH_SIZE), \n",
    "                            (total_acc_val/int(len(in_val) // BATCH_SIZE))*100, total_bleu_val/ int(len(in_val) // BATCH_SIZE)))\n",
    "    \n",
    "    val_loss_history.append(total_loss_val/int(len(in_val) // BATCH_SIZE))\n",
    "    if epoch > 6:\n",
    "        if count >= 4:\n",
    "            print(\"\\n\\nEarlyStopping Invoked!!! Stopping the training\\n\\n\")\n",
    "            break\n",
    "        else:\n",
    "            if val_loss_history[epoch-1] < val_loss_history[epoch]:\n",
    "                print(\"\\n******count++ Increased******\\n\")\n",
    "                count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: ../working/logs/ (stored 0%)\n",
      "  adding: ../working/logs/20200630-090055/ (stored 0%)\n",
      "  adding: ../working/logs/20200630-090055/test/ (stored 0%)\n",
      "  adding: ../working/logs/20200630-090055/test/events.out.tfevents.1593507655.79c031f94454.37.32512298.v2 (deflated 69%)\n",
      "  adding: ../working/logs/20200630-090055/train/ (stored 0%)\n",
      "  adding: ../working/logs/20200630-090055/train/events.out.tfevents.1593507655.79c031f94454.37.32512290.v2 (deflated 69%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r \"../working/final_logs_bleu.zip\" \"../working/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jkadlajsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZDVFHinW5pK"
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkdZ4EKQoxWp",
    "outputId": "105ef609-7862-4669-b8fa-1638b71ac71f"
   },
   "outputs": [],
   "source": [
    "tensorboard --logdir='logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBnMOitoD2tW"
   },
   "outputs": [],
   "source": [
    "def get_img_tensor(image_path, img_name, model_image):\n",
    "    img = tf.io.read_file(image_path + str(img_name))\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (299, 299))\n",
    "    img = tf.keras.applications.xception.preprocess_input(img)\n",
    "    img_features = model_image(tf.constant(img)[None, :])\n",
    "    return img_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtD562TUDoAg"
   },
   "outputs": [],
   "source": [
    "def evaluate(img_name):\n",
    "    hidden =  tf.zeros((1, units))\n",
    "    img_tensor = tf.convert_to_tensor([get_img_tensor(image_path,img_name[0], image_features_model), \n",
    "                                      get_img_tensor(image_path,img_name[1], image_features_model)])\n",
    "    img_features = tf.constant(img_tensor)[None, :]\n",
    "    features_val = encoder(img_features)\n",
    "\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "    result = []\n",
    "    text = \"\"\n",
    "    for i in range(max_len_output):\n",
    "        print(dec_input.shape, features_val.shape, hidden.shape)\n",
    "        predictions, hidden = decoder([dec_input, features_val, hidden])\n",
    "        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
    "        if predicted_id ==0:\n",
    "            word = \"\"\n",
    "        else:\n",
    "            word = tokenizer.index_word[predicted_id]\n",
    "        result.append(word)\n",
    "        text += \" \" + word\n",
    "        if word == '<end>' or word == 'end':\n",
    "            return result, text\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPL1xANqJS9g"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "def test_img_cap(img_data, actual_text):\n",
    "    result, text = evaluate(img_data)\n",
    "    \"\"\"Displays images for given input array of image names\"\"\"\n",
    "    fig, axs = plt.subplots(1, len(img_data), figsize = (10,10), tight_layout=True)\n",
    "    count = 0\n",
    "    for img, subplot in zip(img_data, axs.flatten()):\n",
    "        img_=mpimg.imread(image_path+img)\n",
    "        imgplot = axs[count].imshow(img_, cmap = 'bone')\n",
    "        count +=1\n",
    "    plt.show()\n",
    "    reference = [actual_text.split()[1:-1]]\n",
    "    result = result[:-1]\n",
    "    print(\"=\"*50)\n",
    "    print(\"Actual\", actual_text)\n",
    "    print(\"Predicted:\",text)\n",
    "    print(\"=\"*50)\n",
    "    print('Individual 1-gram: {:.4f} Cumulative 1-gram: {:.4f}'.format(sentence_bleu(reference, result, weights=(1, 0, 0, 0)), sentence_bleu(reference, result, weights=(1, 0, 0, 0))))\n",
    "    print('Individual 2-gram: {:.4f} Cumulative 2-gram: {:.4f}'.format(sentence_bleu(reference, result, weights=(0, 1, 0, 0)), sentence_bleu(reference, result, weights=(0.5, 0.5, 0, 0))))\n",
    "    print('Individual 3-gram: {:.4f} Cumulative 3-gram: {:.4f}'.format(sentence_bleu(reference, result, weights=(0, 0, 1, 0)), sentence_bleu(reference, result, weights=(0.33, 0.33, 0.33, 0))))\n",
    "    print('Individual 4-gram: {:.4f} Cumulative 4-gram: {:.4f}'.format(sentence_bleu(reference, result, weights=(0, 0, 0, 1)), sentence_bleu(reference, result, weights=(0.25, 0.25, 0.25, 0.25))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiTgDD3ZYxPp",
    "outputId": "25149391-a75a-4b59-c801-fc5c4a750846"
   },
   "outputs": [],
   "source": [
    "test_img_cap(in_test[164], out_test[164])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GoEtfMeEAOH",
    "outputId": "e97cf8f8-0711-41b3-8bec-cf89b08a2309"
   },
   "outputs": [],
   "source": [
    "test_img_cap(in_test[64], out_test[64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_aIlqbGFnSf",
    "outputId": "4f503851-363b-457f-bc51-5c54159666d6"
   },
   "outputs": [],
   "source": [
    "test_img_cap(in_test[29], out_test[29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YU7fyfttMcy0",
    "outputId": "e91eb948-d675-4611-8d95-fecc1686c221"
   },
   "outputs": [],
   "source": [
    "test_img_cap(in_test[229], out_test[229])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3gpKVM3Oxi-",
    "outputId": "754bdaa8-328b-4ef8-f71d-b6759c07778a"
   },
   "outputs": [],
   "source": [
    "test_img_cap(in_test[365], out_test[365])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPhpZ7m6SnLE",
    "outputId": "f582efd2-4d1f-4f11-fb51-740fc0cd3f2d"
   },
   "outputs": [],
   "source": [
    "test_img_cap(in_test[363], out_test[363])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSOkmEJa4QGN",
    "outputId": "c30ef652-8339-4045-f64a-3093876f7f3a"
   },
   "outputs": [],
   "source": [
    "test_img_cap(in_test[103], out_test[103])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ne6YdTPL4lHn",
    "outputId": "e35f7d64-71b1-4fdd-97be-4e54dce95c66"
   },
   "outputs": [],
   "source": [
    "test_img_cap(in_test[65], out_test[65])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDE-KAHiTAU-"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "- The model build on Bidirectional LSTM with attention seems better model than than basic model\n",
    "- Loss is converged to 0.3 with accuracy of 89% train and 92% validation from the result we can see there is similarity between each predicted and actual output.\n",
    "- There are some major impression identified in the predicted output if there are any major actual impression.\n",
    "- I have used InceptionV3 model due to its size and tensor output when compared with other imageNet trained model.\n",
    "- Model feature vector is from the pretrained Inception model. weights are save and set to the while model creation.\n",
    "- This feature extracted vector size(1,2048) then input to CNN encoder layer. this encoded vector input to BiLSTM layer. Attention layer gives the weights of (1,Unit_size) for each word by teacher forcing the output vector is input to decoder layer (BiLSTM layer) the predicted value and the attention weights are calculated. Below is the architecture of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuAZky2m50BJ"
   },
   "source": [
    "# Future work\n",
    "- We can also modify the decoder layer with state of the art BERT Transformer instead of attention layer. \n",
    "- We can further increase the Encoder CNN layer to deep layer for improvements.\n",
    "- Deep CNN encoder with Decoder Bert transformer will give better result than this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
